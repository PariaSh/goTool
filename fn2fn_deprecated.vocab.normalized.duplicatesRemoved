TMP=MinNumFX(TMP,TMP)
TMP=WidenXStoXxX(TMP)
TMP=PwMinXSxX(TMP,TMP)
TMP=WidenXUtoXxX(TMP)
TMP=amd64g_calculate_rflags_all(CONST,TMP,TMP,TMP):Ity_IX
TMP=armg_calculate_flag_c(CONST,CONST,CONST,CONST):Ity_IX
TMP=XStoX(TMP)
TMP=CmpGTXUxX(TMP,TMP)
TMP=AddXxX(TMP,TMP)
TMP=if(CONST)ILGop_XStoX(LDle(TMP))elseTMP
TMP=QSalXxX(TMP,TMP)
STle(MEM)=CONST
TMP=DivModSXtoX(TMP,TMP)
TMP=AddX(TMP,CONST)
TMP=amd64g_calculate_condition(CONST,CONST,TMP,TMP,TMP):Ity_IX
TMP=CmpLTXFXxX(CONST,TMP)
TMP=amd64g_calculate_condition(CONST,TMP,TMP,TMP,TMP):Ity_IX
TMP=QNarrowUnXStoXSxX(TMP)
TMP=XHLtoVX(TMP,CONST)
TMP=FXtoFX(TMP,TMP)
TMP=LDle:IX(MEM)
TMP=DivXFXxX(CONST,TMP)
TMP=CmpLEXFXxX(TMP,TMP)
TMP=amd64g_calculate_RCR(TMP,CONST,TMP,CONST):Ity_IX
TMP=DIRTYCONSTTODO(effects):::amd64g_dirtyhelper_loadF80le(TMP)
TMP=armg_calculate_condition(CONST,CONST,TMP,TMP):Ity_IX
TMP=XorVX(TMP,TMP)
TMP=DIRTYCONSTTODO(effects):::amd64g_dirtyhelper_FRSTOR(GSPTR,TMP)
}
TMP=DIRTYCONSTTODO(effects):::armg_dirtyhelper_SHA256H2(VECRET,TMP,TMP,TMP,TMP,TMP,TMP,TMP,TMP,TMP,TMP,TMP,TMP)
TMP=SarNXxX(CONST,CONST)
TMP=QSubXUxX(TMP,TMP)
TMP=QDMullXSxX(TMP,TMP)
TMP=CmpLTXS(CONST,TMP)
TMP=if(CONST)ILGop_XUtoX(LDle(TMP))elseTMP
TMP=ReinterpFXasIX(TMP)
TMP=CONST
TMP=ShlNXxX(CONST,CONST)
TMP=XtoX(TMP)
TMP=if(CONST)ILGop_XUtoX(LDle(CONST))elseTMP
TMP=armg_calculate_flag_v(CONST,TMP,CONST,CONST):Ity_IX
TMP=MullUX(TMP,TMP)
TMP=QAddXUxX(TMP,TMP)
TMP=XorX(CONST,TMP)
TMP=QNarrowUnXUtoXUxX(TMP)
TMP=RSqrtEstXUxX(TMP)
TMP=CatOddLanesXxX(TMP,TMP)
TMP=CmpEQXFxX(TMP,TMP)
TMP=amd64g_calculate_rflags_c(CONST,TMP,TMP,CONST):Ity_IX
TMP=CmpEQX(CONST,TMP)
TMP=FixedXSToFXxX_RN(TMP,CONST)
TMP=AndX(TMP,CONST)
TMP=FXToFixedXUxX_RZ(TMP,CONST)
TMP=PwMaxXUxX(TMP,TMP)
TMP=VXtoX(TMP)
TMP=DIRTYCONSTTODO(effects):::armg_dirtyhelper_AESMC(VECRET,TMP,TMP,TMP,TMP)
TMP=HAddXUxX(TMP,TMP)
TMP=AddXFXxX(TMP,CONST)
TMP=MinXSxX(TMP,TMP)
TMP=armg_calculate_flag_qc(TMP,TMP,TMP,TMP):Ity_IX
TMP=RSqrtEstXFxX(TMP)
TMP=XUtoVX(TMP)
TMP=armg_calculate_flags_nzcv(CONST,TMP,CONST,TMP):Ity_IX
TMP=MulXFXxX(TMP,CONST)
TMP=MulXFXxX(CONST,TMP)
TMP=PwMinXFxX(TMP,TMP)
TMP=ShlX(CONST,TMP)
TMP=DIRTYCONSTTODO(effects):::amd64g_dirtyhelper_FLDENV(GSPTR,TMP)
TMP=DupXxX(TMP)
TMP=amd64g_calculate_condition(CONST,CONST,TMP,CONST,TMP):Ity_IX
TMP=amd64g_calculate_FXAM(TMP,TMP):Ity_IX
TMP=SadXUxX(TMP,TMP)
TMP=AndVX(TMP,CONST)
TMP=CmpEQXFxX(CONST,TMP)
PUT(REG)=TMP
TMP=MullSX(TMP,TMP)
TMP=TMP
TMP=amd64g_calculate_condition(CONST,CONST,TMP,TMP,CONST):Ity_IX
TMP=DIRTYCONSTTODO(effects):::amd64g_dirtyhelper_AES(GSPTR,MEM,MEM,MEM,MEM)
TMP=DivModUXtoX(TMP,CONST)
TMP=ClsXxX(TMP)
TMP=AddXxX(TMP,CONST)
TMP=GET:IX(REG)
TMP=NarrowUnXtoXxX(TMP)
TMP=CmpLTXS(TMP,CONST)
TMP=CmpLTXFXxX(TMP,CONST)
TMP=CmpUNXFXxX(TMP,TMP)
TMP=XUtoX(TMP)
TMP=CmpLTXFXxX(TMP,TMP)
TMP=QRDMulHiXSxX(TMP,TMP)
TMP=QShlNsatSUXxX(TMP,CONST)
TMP=IXUtoFX(TMP)
TMP=MulX(TMP,TMP)
TMP=DIRTYCONSTTODO(effects):::amd64g_dirtyhelper_OUT(MEM,TMP,MEM)
TMP=ReinterpIXasFX(TMP)
TMP=amd64g_calculate_rflags_c(CONST,CONST,CONST,TMP):Ity_IX
TMP=HSubXUxX(TMP,TMP)
TMP=SalXxX(TMP,TMP)
TMP=CmpLEXU(TMP,TMP)
TMP=AddX(CONST,CONST)
TMP=VXHItoX(TMP)
TMP=SarNXxX(TMP,CONST)
TMP=AddXFXxX(TMP,TMP)
TMP=SqrtFX(CONST,TMP)
TMP=amd64g_calculate_rflags_all(TMP,TMP,TMP,TMP):Ity_IX
TMP=PolynomialMullXxX(TMP,TMP)
TMP=IXUtoFxX(TMP)
TMP=ShlX(TMP,TMP)
TMP=DIRTYCONSTTODO(effects):::armg_dirtyhelper_SHA1P(VECRET,TMP,TMP,TMP,TMP,MEM,MEM,MEM,TMP,TMP,TMP,TMP,TMP)
TMP=DivXFXxX(TMP,TMP)
TMP=DIRTYCONSTTODO(effects):::amd64g_dirtyhelper_PCMPxSTRx(GSPTR,MEM,MEM,MEM,TMP,TMP)
TMP=CmpEQXFXxX(TMP,TMP)
TMP=armg_calculate_condition(TMP,TMP,CONST,CONST):Ity_IX
TMP=QSubXSxX(CONST,TMP)
TMP=SubX(CONST,CONST)
TMP=armg_calculate_flag_c(CONST,CONST,TMP,CONST):Ity_IX
TMP=QSubXS(TMP,TMP)
TMP=MinXFxX(TMP,TMP)
TMP=if(TMP)ILGop_XStoX(LDle(TMP))elseTMP
TMP=armg_calculate_flag_c(TMP,TMP,TMP,TMP):Ity_IX
TMP=SubXxX(TMP,TMP)
TMP=SubXFXxX(TMP,CONST)
TMP=FXtoIXS(TMP,TMP)
AbiHint(MEM,REG,TMP)
TMP=PwMaxXSxX(TMP,TMP)
TMP=x86amd64g_calculate_FXTRACT(TMP,CONST):Ity_IX
TMP=PwMaxXFxX(TMP,TMP)
TMP=ShrX(CONST,TMP)
TMP=if(CONST)ILGop_IdentX(LDle(TMP))elseTMP
TMP=CmpLEXFXxX(CONST,TMP)
TMP=amd64g_check_fldcw(TMP):Ity_IX
TMP=amd64g_create_mxcsr(TMP):Ity_IX
TMP=FXtoIXS(CONST,TMP)
TMP=MulX(TMP,CONST)
TMP=AndX(CONST,TMP)
TMP=InterleaveLOXxX(TMP,TMP)
TMP=amd64g_calculate_pclmul(TMP,TMP,CONST):Ity_IX
TMP=if(TMP)ILGop_IdentX(LDle(TMP))elseTMP
TMP=RecipEstXFxX(TMP)
TMP=amd64g_calculate_rflags_all(CONST,CONST,TMP,TMP):Ity_IX
TMP=amd64g_calculate_condition(CONST,CONST,TMP,CONST,CONST):Ity_IX
TMP=armg_calculate_condition(CONST,TMP,TMP,TMP):Ity_IX
TMP=QNarrowBinXStoXSxX(TMP,TMP)
TMP=armg_calculate_condition(CONST,TMP,TMP,CONST):Ity_IX
TMP=DIRTYCONSTTODO(effects):::amd64g_dirtyhelper_AESKEYGENASSIST(GSPTR,MEM,MEM,MEM)
TMP=amd64g_calculate_rflags_all(CONST,TMP,CONST,TMP):Ity_IX
TMP=ITE(TMP,CONST,CONST)
TMP=CmpEQXxX(TMP,TMP)
TMP=QNarrowBinXStoXUxX(TMP,TMP)
TMP=XHLtoX(TMP,TMP)
TMP=CmpLEXS(TMP,TMP)
TMP=SubXxX(CONST,TMP)
Ijk_Boring
TMP=XorX(TMP,CONST)
TMP=amd64g_calculate_RCR(TMP,TMP,TMP,CONST):Ity_IX
TMP=XHLtoVX(CONST,TMP)
TMP=if(TMP)ILGop_XUtoX(LDle(TMP))elseCONST
TMP=FixedXUToFXxX_RN(TMP,CONST)
TMP=QAddXSxX(TMP,TMP)
TMP=armg_calculate_condition(CONST,TMP,CONST,CONST):Ity_IX
TMP=ShlNXxX(TMP,CONST)
TMP=AndX(TMP,TMP)
TMP=amd64g_calculate_rflags_c(TMP,TMP,TMP,CONST):Ity_IX
TMP=OrX(CONST,TMP)
TMP=CmpGTXSxX(TMP,CONST)
TMP=AddXFXxX(CONST,TMP)
TMP=AddX(TMP,TMP)
TMP=MullUX(TMP,CONST)
TMP=ITE(TMP,TMP,CONST)
TMP=SetVXloX(TMP,TMP)
TMP=XUtoVX(CONST)
TMP=CtzX(TMP)
TMP=if(TMP)ILGop_IdentX(LDle(CONST))elseCONST
TMP=RecipStepXFxX(TMP,TMP)
TMP=CmpGTXSxX(CONST,TMP)
TMP=armg_calculate_flag_v(CONST,TMP,CONST,TMP):Ity_IX
TMP=amd64g_calculate_RCL(TMP,CONST,TMP,CONST):Ity_IX
TMP=PolynomialMulXxX(TMP,TMP)
TMP=ShrX(TMP,TMP)
TMP=CmpNEX(CONST,TMP)
TMP=CmpLEXS(TMP,CONST)
TMP=ShlX(CONST,CONST)
TMP=amd64g_calculate_rflags_c(TMP,TMP,TMP,TMP):Ity_IX
TMP=DivModSXtoX(TMP,CONST)
TMP=CmpNEX(TMP,CONST)
TMP=amd64g_calculate_rflags_all(CONST,TMP,CONST,CONST):Ity_IX
TMP=CmpGTXSxX(TMP,TMP)
TMP=armg_calculate_condition(CONST,CONST,TMP,CONST):Ity_IX
TMP=XHItoX(TMP)
TMP=CmpLEXU(CONST,CONST)
TMP=armg_calculate_flag_n(TMP,TMP,TMP,TMP):Ity_IX
TMP=CmpGEXFxX(TMP,TMP)
TMP=armg_calculate_flag_z(TMP,TMP,TMP,TMP):Ity_IX
TMP=XHLtoX(CONST,TMP)
TMP=CmpFX(TMP,TMP)
TMP=DIRTYCONSTTODO(effects):::amd64g_dirtyhelper_loadF80le(MEM)
TMP=NegFX(TMP)
TMP=ShrNXxX(CONST,CONST)
TMP=CmpLEXS(CONST,CONST)
TMP=CmpNEZXxX(TMP)
TMP=IXStoFX(TMP,TMP)
TMP=if(TMP)ILGop_XUtoX(LDle(TMP))elseTMP
{
TMP=AddX(CONST,TMP)
TMP=amd64g_calculate_rflags_c(CONST,TMP,CONST,TMP):Ity_IX
TMP=ClzX(TMP)
TMP=ShrX(TMP,CONST)
TMP=RoundFXtoInt(CONST,TMP)
TMP=ShrXxX(TMP,TMP)
TMP=if(TMP)ILGop_IdentX(LDle(CONST))elseTMP
TMP=FXtoFX(TMP)
TMP=AbsFX(TMP)
TMP=DIRTYCONSTTODO(effects):::amd64g_dirtyhelper_RDTSC()
TMP=armg_calculate_flag_c(CONST,TMP,CONST,CONST):Ity_IX
TMP=OrX(TMP,TMP)
TMP=DivXFXxX(CONST,CONST)
TMP=amd64g_calculate_rflags_c(CONST,CONST,CONST,CONST):Ity_IX
TMP=RSqrtStepXFxX(TMP,TMP)
TMP=MaxXUxX(TMP,TMP)
TMP=GetMSBsXxX(CONST)
TMP=SubX(TMP,TMP)
TMP=SubX(TMP,CONST)
TMP=DIRTYCONSTTODO(effects):::amd64g_dirtyhelper_storeF80le(TMP,TMP)
TMP=FXToFixedXSxX_RZ(TMP,CONST)
TMP=amd64g_calculate_condition(CONST,CONST,CONST,TMP,TMP):Ity_IX
TMP=QAddXS(TMP,TMP)
TMP=armg_calculate_condition(TMP,TMP,CONST,TMP):Ity_IX
TMP=HAddXSxX(TMP,TMP)
TMP=QDMulHiXSxX(TMP,TMP)
TMP=ReinterpIXasFX(CONST)
TMP=amd64g_calculate_rflags_c(CONST,TMP,CONST,CONST):Ity_IX
TMP=DIRTYCONSTTODO(effects):::armg_dirtyhelper_VMULLP64(VECRET,TMP,TMP,TMP,TMP)
TMP=CmpLTXU(CONST,TMP)
TMP=CmpLEXFXxX(TMP,CONST)
TMP=InterleaveHIXxX(CONST,TMP)
TMP=armg_calculate_flag_c(CONST,TMP,TMP,TMP):Ity_IX
TMP=CmpEQX(TMP,TMP)
TMP=IXStoFX(TMP)
TMP=SubX(CONST,TMP)
TMP=CmpGTXFxX(TMP,TMP)
TMP=XorVX(TMP,CONST)
TMP=MinXFXxX(TMP,TMP)
TMP=MullXUxX(TMP,TMP)
TMP=VXHLtoVX(TMP,TMP)
TMP=ShlNXxX(TMP,TMP)
TMP=MulXFxX(TMP,TMP)
PUT(REG)=MEM
TMP=CasCmpEQX(TMP,CONST)
TMP=DIRTYCONSTTODO(effects):::armg_dirtyhelper_SHA1SU0(VECRET,TMP,TMP,TMP,TMP,TMP,TMP,TMP,TMP,TMP,TMP,TMP,TMP)
TMP=MulXFXxX(TMP,TMP)
TMP=ITE(TMP,TMP,TMP)
TMP=CmpEQX(CONST,CONST)
TMP=QNarrowUnXStoXUxX(TMP)
TMP=MullSX(CONST,TMP)
TMP=CmpEQXxX(CONST,CONST)
TMP=DIRTYCONSTTODO(effects):::amd64g_dirtyhelper_IN(MEM,MEM)
TMP=CmpLTXU(CONST,CONST)
TMP=DIRTYCONSTTODO(effects):::amd64g_dirtyhelper_FNSAVE(GSPTR,TMP)
TMP=RecipEstXUxX(TMP)
TMP=SarX(TMP,TMP)
TMP=OrVX(TMP,TMP)
TMP=armg_calculate_condition(CONST,TMP,CONST,TMP):Ity_IX
TMP=DIRTYCONSTTODO(effects):::amd64g_dirtyhelper_CPUID_avx2(GSPTR)
TMP=ReverseXsInX_xX(TMP)
STle(MEM)=TMP
TMP=DIRTYCONSTTODO(effects):::amd64g_dirtyhelper_IN(TMP,MEM)
TMP=PermXxX(TMP,CONST)
TMP=amd64g_create_fpucw(TMP):Ity_IX
TMP=DivModUXtoX(CONST,TMP)
TMP=QShlNsatUUXxX(TMP,CONST)
TMP=PwAddXFxX(TMP,TMP)
TMP=armg_calculate_flag_c(CONST,TMP,CONST,TMP):Ity_IX
TMP=SarXxX(TMP,TMP)
TMP=if(CONST)ILGop_IdentX(LDle(CONST))elseTMP
MBusEvent-event
TMP=SubXFxX(TMP,TMP)
TMP=ITE(TMP,CONST,TMP)
TMP=ExpCmpNEX(TMP,CONST)
TMP=CmpLTXU(TMP,CONST)
TMP=MullUX(CONST,TMP)
TMP=CmpNEX(TMP,TMP)
TMP=CmpEQXxX(CONST,TMP)
TMP=SarX(TMP,CONST)
TMP=CmpEQX(TMP,CONST)
TMP=armg_calculate_flag_v(TMP,TMP,TMP,TMP):Ity_IX
PutI(REG)[MEM,REG]=MEM
TMP=MaxXSxX(TMP,TMP)
if(TMP)STle(MEM)=CONST
TMP=CmpNEZXxX(CONST)
TMP=armg_calculate_condition(CONST,CONST,CONST,CONST):Ity_IX
TMP=NotVX(TMP)
TMP=GetElemXxX(CONST,CONST)
TMP=amd64g_calculate_rflags_all(CONST,CONST,CONST,TMP):Ity_IX
TMP=VXtoVX_X(TMP)
TMP=XorX(TMP,TMP)
PUT(REG)=CONST
TMP=if(TMP)ILGop_XStoX(LDle(CONST))elseTMP
TMP=RoundFXtoInt(TMP,TMP)
TMP=QShlNsatSSXxX(TMP,CONST)
TMP=MaxXFxX(TMP,TMP)
TMP=MulX(CONST,TMP)
TMP=SarX(CONST,TMP)
TMP=DivModUXtoX(TMP,TMP)
TMP=XHLtoVX(TMP,TMP)
TMP=ShrNXxX(TMP,TMP)
TMP=armg_calculate_flag_c(CONST,TMP,TMP,CONST):Ity_IX
TMP=armg_calculate_flag_v(CONST,TMP,TMP,CONST):Ity_IX
TMP=DIRTYCONSTTODO(effects):::amd64g_dirtyhelper_PCMPxSTRx(GSPTR,MEM,MEM,MEM,MEM,MEM)
TMP=AndX(CONST,CONST)
TMP=XHLtoVX(CONST,CONST)
TMP=amd64g_calculate_RCL(CONST,TMP,TMP,CONST):Ity_IX
TMP=CatEvenLanesXxX(TMP,TMP)
TMP=armg_calculate_condition(TMP,TMP,TMP,TMP):Ity_IX
TMP=PwAddLXUxX(TMP)
TMP=amd64g_check_ldmxcsr(TMP):Ity_IX
TMP=PwAddLXSxX(TMP)
TMP=SubXFXxX(CONST,TMP)
TMP=XHLtoX(CONST,CONST)
TMP=amd64g_calculate_rflags_c(CONST,TMP,TMP,TMP):Ity_IX
TMP=AbsXFxX(TMP)
TMP=PermXxX(TMP,TMP)
TMP=MaxXFXxX(TMP,TMP)
TMP=MullXSxX(TMP,TMP)
TMP=armg_calculate_flag_v(CONST,CONST,TMP,CONST):Ity_IX
TMP=AndVX(TMP,TMP)
TMP=amd64g_calculate_condition(CONST,CONST,CONST,CONST,TMP):Ity_IX
TMP=SqrtXFXxX(TMP)
TMP=CmpLTXU(TMP,TMP)
TMP=CmpGTXUxX(CONST,TMP)
TMP=CasCmpNEX(TMP,TMP)
TMP=IXStoFX(TMP,CONST)
TMP=AddXFxX(TMP,TMP)
TMP=if(CONST)ILGop_IdentX(LDle(TMP))elseCONST
TMP=DIRTYCONSTTODO(effects):::amd64g_dirtyhelper_FSTENV(GSPTR,TMP)
TMP=MulXxX(TMP,TMP)
TMP=CmpEQXxX(TMP,CONST)
TMP=if(TMP)ILGop_IdentX(LDle(TMP))elseCONST
TMP=QShlXxX(TMP,TMP)
TMP=HSubXSxX(TMP,TMP)
TMP=SubXxX(TMP,CONST)
TMP=InterleaveHIXxX(TMP,TMP)
TMP=PwMinXUxX(TMP,TMP)
TMP=XHLtoX(TMP,CONST)
TMP=CntXxX(TMP)
TMP=CmpLEXS(CONST,TMP)
TMP=amd64g_calculate_rflags_c(CONST,CONST,TMP,TMP):Ity_IX
TMP=if(TMP)ILGop_XStoX(LDle(TMP))elseCONST
TMP=DivModSXtoX(CONST,TMP)
TMP=XorVX(CONST,TMP)
TMP=CmpLTXS(TMP,TMP)
TMP=QSubXSxX(TMP,TMP)
TMP=SubXFXxX(TMP,TMP)
if(TMP)
TMP=armg_calculate_condition(TMP,TMP,TMP,CONST):Ity_IX
TMP=if(TMP)ILGop_XUtoX(LDle(CONST))elseTMP
TMP=GetElemXxX(TMP,CONST)
TMP=MinXUxX(TMP,TMP)
TMP=NotX(TMP)
TMP=amd64g_calculate_RCL(TMP,TMP,TMP,CONST):Ity_IX
TMP=armg_calculate_condition(CONST,CONST,CONST,TMP):Ity_IX
TMP=InterleaveLOXxX(CONST,TMP)
TMP=ShrNXxX(TMP,CONST)
TMP=ClzXxX(TMP)
TMP=ShlXxX(TMP,TMP)
TMP=OrX(TMP,CONST)
TMP=DivXFXxX(TMP,CONST)
if(TMP)STle(MEM)=TMP
TMP=armg_calculate_flag_v(CONST,TMP,TMP,TMP):Ity_IX
TMP=DIRTYCONSTTODO(effects):::amd64g_dirtyhelper_OUT(TMP,TMP,MEM)
TMP=GetI(REG)[MEM,REG]
TMP=XtoX(CONST)
TMP=GetMSBsXxX(TMP)
TMP=armg_calculate_flag_v(CONST,CONST,CONST,CONST):Ity_IX
TMP=CmpLEXU(CONST,TMP)
t(CONST,CONST)=CASle(MEM::(TMP,TMP)->(TMP,TMP))
TMP=PwAddXxX(TMP,TMP)
TMP=ShlX(TMP,CONST)
TMP=CmpLEXU(TMP,CONST)
TMP=MullSX(TMP,CONST)
TMP=CmpwNEZX(TMP)
TMP=MaxNumFX(TMP,TMP)
